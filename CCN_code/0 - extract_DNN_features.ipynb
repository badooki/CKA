{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5f27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from data_utils import get_tvsd_dataset, load_data, THINGSDataset\n",
    "from moment_utils import *\n",
    "\n",
    "DATAROOT = './'\n",
    "ACTIVATIONS_ROOT = os.path.join(DATAROOT, 'TVSD', 'TVSD_activations')\n",
    "RESULTS_ROOT = os.path.join(DATAROOT, 'TVSD', 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e22db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(DATAROOT)\n",
    "\n",
    "sub_names = ['F', 'N']\n",
    "roi_names = ['V1', 'V4', 'IT']\n",
    "\n",
    "roi_data = {}\n",
    "for sub_name in sub_names:\n",
    "\n",
    "    roi_data[sub_name] = {}\n",
    "    for roi_name in roi_names:\n",
    "        roi = np.asarray(data[sub_name]['df'][roi_name].tolist())\n",
    "        roi_data[sub_name][roi_name] = roi\n",
    "\n",
    "\n",
    "# Store the local paths of images\n",
    "all_image_paths = {}\n",
    "for name in ['F', 'N']:\n",
    "\n",
    "    image_paths = {}\n",
    "    for path in data[name]['df'].things_path:\n",
    "        cn, fn = path.split('\\\\')\n",
    "\n",
    "        if cn not in image_paths:\n",
    "            image_paths[cn] = [fn]\n",
    "        else:\n",
    "            image_paths[cn] += [fn]\n",
    "\n",
    "    all_image_paths[name] = image_paths\n",
    "    \n",
    "for key in image_paths.keys():\n",
    "    assert np.sum(all_image_paths['F'][key] != all_image_paths['N'][key]) == 0\n",
    "    \n",
    "IMAGE_PATHS = image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9519dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef5015b-b32e-4e76-9d7a-afe5abc5b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "THINGS_ROOT = os.path.join(DATAROOT, 'THINGS')\n",
    "THINGS_DATASET = os.path.join(THINGS_ROOT, 'images')\n",
    "TRAIN_FOLDER = os.path.join(THINGS_DATASET, 'imgs_train')\n",
    "\n",
    "layer_names_resnet18 = ['conv1', 'maxpool',\n",
    "                        'layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2',\n",
    "                        'layer2.0.conv1', 'layer2.0.conv2', 'layer2.1.conv1', 'layer2.1.conv2',\n",
    "                        'layer3.0.conv1', 'layer3.0.conv2', 'layer3.1.conv1', 'layer3.1.conv2',\n",
    "                        'layer4.0.conv1', 'layer4.0.conv2', 'layer4.1.conv1', 'layer4.1.conv2',\n",
    "                        'avgpool', 'fc']\n",
    "\n",
    "layer_names_cornet_s = ['V1.conv1', 'V1.conv2', 'V2.conv1', 'V2.conv2', 'V2.conv3',\n",
    "                        'V4.conv1', 'V4.conv2', 'V4.conv3', 'IT.conv1', 'IT.conv2', 'IT.conv3',\n",
    "                        'decoder.avgpool', 'decoder.linear']\n",
    "\n",
    "model_dict = {'resnet18': {'layers': layer_names_resnet18,\n",
    "                           'source': 'torchvision'},\n",
    "              'cornet-s': {'layers': layer_names_cornet_s,\n",
    "                           'source': 'custom'}\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78449915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_things_activations(model_name, layer_name):\n",
    "\n",
    "    model_info = model_dict[model_name]\n",
    "    layer_names = model_info['layers']\n",
    "    source = model_info['source']\n",
    "\n",
    "    assert layer_name in layer_names, f\"Layer {layer_name} not in model {model_name}.\"\n",
    "\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    from thingsvision import get_extractor\n",
    "    from thingsvision.utils.storing import save_features\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    batch_size = 64\n",
    "\n",
    "    extractor = get_extractor(model_name=model_name,\n",
    "                              source=source,\n",
    "                              device=device,\n",
    "                              pretrained=True\n",
    "                              )\n",
    "    extractor.show_model()\n",
    "\n",
    "    dataset = THINGSDataset(root=TRAIN_FOLDER,\n",
    "                            path_dict=IMAGE_PATHS,\n",
    "                            transform=extractor.get_transformations()\n",
    "                            )\n",
    "\n",
    "    batches = DataLoader(dataset=dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=8,\n",
    "                         pin_memory=True,\n",
    "                         pin_memory_device=device,\n",
    "                         )\n",
    "\n",
    "    print(f\"Processing: {model_name} {layer_name}\")\n",
    "    save_folder = Path(ACTIVATIONS_ROOT) / 'models' / model_name\n",
    "    save_path = save_folder / layer_name\n",
    "    features = extractor.extract_features(batches=batches,\n",
    "                                          module_name=layer_name,\n",
    "                                          flatten_acts=True,\n",
    "                                          output_type='tensor'\n",
    "                                          )\n",
    "    save_features(features, out_path=save_path, file_format='npy')\n",
    "\n",
    "    return features.numpy()\n",
    "\n",
    "\n",
    "def get_things_activations(model_name, layer_name):\n",
    "\n",
    "    model_info = model_dict[model_name]\n",
    "    layer_names = model_info['layers']\n",
    "    source = model_info['source']\n",
    "\n",
    "    save_folder = Path(ACTIVATIONS_ROOT) / 'models' / model_name\n",
    "    save_path = save_folder / layer_name\n",
    "\n",
    "    if os.path.isfile(save_path / f'features.npy'):\n",
    "        print('Loading activations for layer:', model_name, layer_name)\n",
    "        features = np.load(save_path / f'features.npy')\n",
    "    else:\n",
    "        features = extract_things_activations(model_name, layer_name)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "model_name = 'cornet-s'\n",
    "layer_name = 'IT.conv2'\n",
    "\n",
    "acts = get_things_activations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df2219b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ab31f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 2000\n",
    "Q = 100\n",
    "num_repeat = 200\n",
    "\n",
    "filename = f'./all_ckas_P_{P}_Q_{Q}_rep_{num_repeat}.npz'\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "\n",
    "    all_data = {}\n",
    "    for sub_name in sub_names:\n",
    "        subject_data = {}\n",
    "        for model_name in model_dict.keys():\n",
    "\n",
    "            layers = model_dict[model_name]['layers']\n",
    "\n",
    "            model_subject_ckas = {key: [] for key in roi_names}\n",
    "            for layer_name in layers:\n",
    "\n",
    "                Psi = get_things_activations(model_name, layer_name)\n",
    "\n",
    "                for roi_name in roi_names:\n",
    "\n",
    "                    Phi = roi_data[sub_name][roi_name]\n",
    "\n",
    "                    print('\\r{} {}, {}, {}'.format(sub_name, roi_name, model_name, layer_name))\n",
    "\n",
    "                    trials = []\n",
    "                    for i in range(num_repeat):\n",
    "\n",
    "                        idx_P = np.random.choice(np.arange(Phi.shape[0]), P, replace=False)\n",
    "                        idx_Qa = np.random.choice(np.arange(Phi.shape[1]), Q, replace=False)\n",
    "                        idx_Qb = np.random.choice(np.arange(Psi.shape[1]), Q, replace=False)\n",
    "\n",
    "                        Phi_a = Phi[:, idx_Qa][idx_P, :]\n",
    "                        Phi_b = Psi[:, idx_Qb][idx_P, :]\n",
    "\n",
    "                        # Calculate estimated numerator using Naive, Song and ours\n",
    "                        num = list(getest_all(Phi_a, Phi_b, indep_cols=True))\n",
    "\n",
    "                        # Calculate estimated denominators using Naive, Song and ours\n",
    "                        denom1 = list(getest_all(Phi_a, Phi_a, indep_cols=False))\n",
    "                        denom2 = list(getest_all(Phi_b, Phi_b, indep_cols=False))\n",
    "\n",
    "                        trials.append([num, denom1, denom2])\n",
    "\n",
    "                    model_subject_ckas[roi_name].append(trials)\n",
    "                subject_data[model_name] = model_subject_ckas\n",
    "            all_data[sub_name] = subject_data\n",
    "\n",
    "    np.savez(filename, all_data=all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaea04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_total = 22248\n",
    "P = 2000\n",
    "Q = 5000\n",
    "num_repeat = 100\n",
    "\n",
    "Q_n_ratio = 1/16\n",
    "\n",
    "filename = f\"./all_models_Pl_{P}_Qb_{Q}_inv_Qratio_{int(1/Q_n_ratio)}_rep_{num_repeat}.npz\"\n",
    "\n",
    "np.random.seed(0)\n",
    "idx_P = np.random.choice(np.arange(P_total), P, replace=False)\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "\n",
    "    all_data = {}\n",
    "    for sub_name in sub_names:\n",
    "        subject_data = {}\n",
    "        for model_name in model_dict.keys():\n",
    "\n",
    "            layers = model_dict[model_name]['layers']\n",
    "\n",
    "            model_subject_ckas = {key: [] for key in roi_names}\n",
    "            for layer_name in layers:\n",
    "\n",
    "                Psi = get_things_activations(model_name, layer_name)\n",
    "\n",
    "                for roi_name in roi_names:\n",
    "\n",
    "                    Phi = roi_data[sub_name][roi_name]\n",
    "                    Pa, Qa = Phi.shape\n",
    "\n",
    "                    print('\\r{} {}, {}, {}'.format(sub_name, roi_name, model_name, layer_name))\n",
    "\n",
    "                    trials = []\n",
    "                    for i in range(num_repeat):\n",
    "\n",
    "                        # idx_P = np.random.choice(np.arange(Phi.shape[0]), P, replace=False)\n",
    "                        idx_Qa = np.random.choice(np.arange(Phi.shape[1]), int(Qa*Q_n_ratio), replace=False)\n",
    "                        idx_Qb = np.random.choice(np.arange(Psi.shape[1]), Q, replace=False)\n",
    "\n",
    "                        Phi_a = Phi[:, idx_Qa][idx_P, :]\n",
    "                        Phi_b = Psi[:, idx_Qb][idx_P, :]\n",
    "\n",
    "                        # Calculate estimated numerator using Naive, Song and ours\n",
    "                        num = list(getest_all(Phi_a, Phi_b, indep_cols=True))\n",
    "\n",
    "                        # Calculate estimated denominators using Naive, Song and ours\n",
    "                        denom1 = list(getest_all(Phi_a, Phi_a, indep_cols=False))\n",
    "                        denom2 = list(getest_all(Phi_b, Phi_b, indep_cols=False))\n",
    "\n",
    "                        trials.append([num, denom1, denom2])\n",
    "\n",
    "                    model_subject_ckas[roi_name].append(trials)\n",
    "                subject_data[model_name] = model_subject_ckas\n",
    "            all_data[sub_name] = subject_data\n",
    "\n",
    "    np.savez(filename, all_data=all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56c521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_for_roi = {'resnet18': {'V1': layer_names_resnet18[1],\n",
    "                              'V4': layer_names_resnet18[10],\n",
    "                              'IT': layer_names_resnet18[14]},\n",
    "                 'cornet-s': {'V1': layer_names_cornet_s[1],\n",
    "                              'V4': layer_names_cornet_s[2],\n",
    "                              'IT': layer_names_cornet_s[5]}}\n",
    "\n",
    "P_total = 22248\n",
    "P = 2000\n",
    "Q = 5000\n",
    "num_repeat = 100\n",
    "\n",
    "Q_neuron_ratios = np.power(1/2, np.linspace(4, 1, 6))\n",
    "\n",
    "filename = f\"./all_models_Pl_{P}_Qb_{Q}_sweep_Qnratio_rep_{num_repeat}.npz\"\n",
    "\n",
    "np.random.seed(0)\n",
    "idx_P = np.random.choice(np.arange(P_total), P, replace=False)\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "\n",
    "    all_data = {}\n",
    "    for sub_name in sub_names:\n",
    "        subject_data = {}\n",
    "        for model_name in model_dict.keys():\n",
    "\n",
    "            model_subject_ckas = {key: [] for key in roi_names}\n",
    "            for Q_n_ratio in Q_neuron_ratios:\n",
    "\n",
    "                for roi_name in roi_names:\n",
    "\n",
    "                    layer_name = layer_for_roi[model_name][roi_name]\n",
    "                    Psi = get_things_activations(model_name, layer_name)\n",
    "                    Phi = roi_data[sub_name][roi_name]\n",
    "                    Pa, Qa = Phi.shape\n",
    "\n",
    "                    print('\\r{} {}, {}, {:.3f}'.format(sub_name, roi_name, model_name, Q_n_ratio))\n",
    "\n",
    "                    trials = []\n",
    "                    for i in range(num_repeat):\n",
    "\n",
    "                        # idx_P = np.random.choice(np.arange(Phi.shape[0]), P, replace=False)\n",
    "                        idx_Qa = np.random.choice(np.arange(Phi.shape[1]), int(Qa*Q_n_ratio), replace=False)\n",
    "                        idx_Qb = np.random.choice(np.arange(Psi.shape[1]), Q, replace=False)\n",
    "\n",
    "                        Phi_a = Phi[:, idx_Qa][idx_P, :]\n",
    "                        Phi_b = Psi[:, idx_Qb][idx_P, :]\n",
    "\n",
    "                        # Calculate estimated numerator using Naive, Song and ours\n",
    "                        num = list(getest_all(Phi_a, Phi_b, indep_cols=True))\n",
    "\n",
    "                        # Calculate estimated denominators using Naive, Song and ours\n",
    "                        denom1 = list(getest_all(Phi_a, Phi_a, indep_cols=False))\n",
    "                        denom2 = list(getest_all(Phi_b, Phi_b, indep_cols=False))\n",
    "\n",
    "                        trials.append([num, denom1, denom2])\n",
    "\n",
    "                    model_subject_ckas[roi_name].append(trials)\n",
    "                subject_data[model_name] = model_subject_ckas\n",
    "            all_data[sub_name] = subject_data\n",
    "\n",
    "    Q_lists = {}\n",
    "    for sub_name in sub_names:\n",
    "        for roi_name in roi_names:\n",
    "            Phi = roi_data[sub_name][roi_name]\n",
    "            Pa, Qa = Phi.shape\n",
    "            Q_lists[(sub_name, roi_name)] = [int(Qa*Q_n_ratio) for Q_n_ratio in Q_neuron_ratios]\n",
    "\n",
    "    np.savez(filename, all_data=all_data, Q_lists=Q_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e134f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ede78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (ffcv)",
   "language": "python",
   "name": "ffcv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
